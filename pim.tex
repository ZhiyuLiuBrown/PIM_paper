%\section{Processing in Memory}
%\label{section:model}
\section{Hardware Architecture}


%\subsection{Hardware model}
\label{section:hardware_model}

In an example architecture utilizing PIM memory \cite{Ahn2015:2, Zhang2014:TTP, Ahn2015:1}, 
multiple CPUs are connected to the main
memory, via a shared crossbar network, as illustrated in Figure \ref{figure:model}.
The main memory consists of two parts---one is a standard DRAM accessible by CPUs 
and the other, called the \textit{PIM memory}, is divided into multiple partitions, 
called \textit{PIM vaults} or simply vaults.  
According to the \textit{Hybrid Memory Cube} specification 1.0 \cite{website:HMC}, 
each HMC consists of 16 or 
32 vaults and has a total size of 2GB or 4 GB (so each vault has size roughly 100MB).\footnote{
These small sizes are preliminary, and it is expected that each vault will be bigger when the 
PIM memory will be commercialized.} 
We assume the same specifications in our PIM model, although the size of a PIM memory and 
the number of its vaults can be bigger. 
Each CPU core also has access to a hierarchy of L1 and L2 caches backed by DRAM,
and a last level cache shared among multiple cores. 

\begin{figure}[ht!]
%$\hrulefill$
%\\
%\\
\centering
\includegraphics[width=.6\linewidth]{model.eps}
%$\hrulefill$
\caption{An example PIM architecture}
\label{figure:model}
\end{figure}

Each vault has a \textit{PIM core} directly attached to it.
We say a vault is \textit{local} to the PIM core attached to it, and vice versa.
A PIM core is a lightweight CPU that may be slower than a full-fledged CPU
with respect to computation speed \cite{Ahn2015:2}. 
A PIM core can be thought of as an in-order CPU with a small private L1 cache.
A vault can be accessed only by its local PIM core.\footnote{
Alternatively, we could assume that a PIM core has direct access to remote vaults, at a larger cost. }
Recent work has proposed efficient cache coherence mechanisms between PIM cores and CPUs  
(e.g., \cite{boroumand2016, Ahn2015:1}), but this introduces additional complexity. 
We show that we design efficient concurrent data structures even if there is no coherence.
Although a PIM core has lower performance than a state-of-the-art CPU core, 
it has fast access to its local vault.

A PIM core communicates with other PIM cores and CPUs via messages.
Each PIM core, as well as each CPU, has buffers for storing incoming messages.
A message is guaranteed to eventually arrive at the buffer of its receiver.
Messages from the same sender to the same receiver are delivered in FIFO order: 
the message sent first arrives at the receiver first. 
However, messages from different senders or to different receivers can arrive in an arbitrary order. 

We assume that a PIM core can only perform read and write operations 
to its local vault, while a CPU also supports more powerful atomic operations, such as \emph{Compare-And-Swap (CAS)} 
and \emph{Fetch-And-Increment (F$\&$A)}.
Virtual memory can be realized efficiently if  
each PIM core maintains its own page table for the local vault~\cite{hsieh2016accelerating}.