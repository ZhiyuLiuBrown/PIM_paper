\section{Related Work}
\label{section:related_work}
The PIM model is undergoing a renaissance.  Studied for decades (e.g.,
\cite{Stone1970, Kogge1994, Gokhale1995, Patterson1997, Oskin1998,
  KangHYKGLTP99, Hall1999, Elliott:1992}), this model has recently
re-emerged due to advances in 3D-stacked techology that can stack
memory dies on top of a logic layer \cite{jeddeloh2012, Loh2008,
  Black2006, Kim2014HotChip, Lee:2016:SMA:2836331.2832911}.  For
example, a 3D-stacked memory prototype called the Hybrid Memory Cube
\cite{website:HMC} was recently released by industry, and the model
has again become the focus of architectural research.  Different
PIM-based architectures have been proposed, either for general purpose
workloads or for specific applications \cite{Ahn2015:1, Ahn2015:2,
  Zhang2014:TTP, hsieh2016accelerating, Azarkhish16, Akin2015:DRM,
  Azarkhish2015, AzarkhishPRLB17, boroumand2016, ZhuASSHPF13,
  ZhuGSPF13, Seshadri:2015, Hashemi:2016, Hashemi:2016b,
  Hsieh:2016:TOM, Seshadri:2013, DBLP:journals/corr/SeshadriLMHBKKM16,
  DBLP:conf/hpca/ChangNLGQM16, DBLP:journals/corr/SeshadriM16}.

The PIM model has several advantages, including low energy consumption and high bandwidth 
(e.g., \cite{Ahn2015:2, Zhang2014:TTP, ZhuASSHPF13, AzarkhishPRLB17}). 
Here, we focus on one more: low memory access latency 
\cite{Loh2008, hsieh2016accelerating, Azarkhish16, Hashemi:2016}.
To our knowledge, we are the first to utilize PIM memory for designing efficient \emph{concurrent data structures}. 
Although some researchers have studied how PIM memory can help speed up concurrent 
operations to data structures, such as parallel graph processing \cite{Ahn2015:2} and  
parallel pointer chasing on linked data structures \cite{hsieh2016accelerating}, 
the applications they consider require very simple, if any, synchronization between operations. 
In contrast, operations to concurrent data structures can interleave in arbitrary orders, 
and therefore have to correctly synchronize with one another in all possible execution scenarios. 
This makes designing concurrent data structures with correctness guarantees, like 
linearizability \cite{Herlihy90}, very challenging. 

No prior work compares the performance of data structures in the PIM model 
with that of state-of-the-art concurrent data structures in the classical shared memory model. 
We analyze and evaluate concurrent linked-lists and skip-lists, 
as representatives of pointer-chasing data structures, and concurrent FIFO queues, 
as representatives of contended data structures.
For linked-lists, we compare our PIM-managed implementation with well-known approaches 
such as fine-grained locking \cite{Heller05} and flat combining 
\cite{Hendler10, Fatourou12, Hendler:2010:DISC}.
For skip-lists, we compare our implementation with a lock-free skip-list \cite{Herlihy08} 
and a skip-list with flat combining and the partitioning optimization. 
For FIFO queues, we compare our implementation with the flat-combining FIFO queue 
\cite{Hendler10} and the F\&A-based FIFO queue \cite{Morrison13}. 
