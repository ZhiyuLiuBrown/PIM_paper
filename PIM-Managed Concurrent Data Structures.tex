\documentclass{sig-alternate-05-2015}

%\documentclass[10pt]{article}   	

\usepackage{verbatim}

\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
%\usepackage[boxed, linesnumbered]{algorithm2e}

\usepackage{subfigure}

\usepackage{epstopdf}

\usepackage{multicol}

\newtheorem{theorem}{Theorem}%[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{property}[theorem]{Property}

\newcommand{\sq}{\hbox{\rlap{$\sqcap$}$\sqcup$}}
%\newcommand{\qed}{\hspace*{\fill}\sq}

%\newenvironment{proof}{\noindent {\bf Proof.}\ }{\qed\par\vskip 4mm\par}
%\newenvironment{proofof}[1]{\bigskip \noindent {\bf Proof of #1:}\quad }{\qed\par\vskip 4mm\par}

\newcommand{\latpim} {\mathcal{L}_{pim}}
\newcommand{\latcpu} {\mathcal{L}_{cpu}}
\newcommand{\latllc} {\mathcal{L}_{llc}}
\newcommand{\latato} {\mathcal{L}_{atomic}}
\newcommand{\latmes} {\mathcal{L}_{message}}
\newcommand{\Sp}{\mathcal{S}_{p}}

\title{Concurrent Data Structures for Near-Memory Computing}
\author{}
\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle

\begin{abstract}
The process-in-memory (near-memory or PIM) model has reemerged and drawn a lot of attention recently,
as breakthroughs on 3D die-stacked technology make PIM architectures viable.
In the PIM model, some lightweight computing units, called PIM cores, are directly attached to
the main memory, making memory access by PIM cores much faster than by CPUs.
Researchers have already shown significant performance improvements on applications,
such as embarrassingly parallel, data-intensive algorithms and
pointer-chasing traversals in sequential data structures, in PIM architectures.

In this paper, we explore ways to design efficient concurrent data structures in the PIM model.
We consider linked-list and skip-list, as examples of pointer-chasing data structures,
and FIFO queue, as an example of contended data structures.
Designing and implementing concurrent data structures with the normal DRAM memory
is known to be notoriously hard for non-experts.
We show that in the PIM model, PIM-managed concurrent data structures can be much simpler.
With the help of different optimizations, such as combining, partitioning and pipelining,
our PIM-managed concurrent data structures can in theory be better than, or at least as good as,
all other existing algorithms we are aware of, based on our performance model.
Our preliminary experiments that indirectly compare our PIM-managed concurrent data structures
with other algorithms also indicate that our algorithms are expected to outperform others.
\end{abstract}

%\newpage
%\ 
%\newpage


\input{intro}
\input{pim}
\input{model}
\input{pointer_chasing}
\input{contended}
\input{related}
%\input{conclusion}


\bibliographystyle{abbrv}
\bibliography{refs_pim}



\begin{comment}
\appendix

\section{Parallelism of memory accesses}
If the distribution of requests to the PIM-managed skip-list is very sharp, that is,
a lot of requests hit a small range of keys, we may have to rebalance the skip-list too often,
incurring significant performance overhead.
However, if we don't rebalance the skip-list frequently,
a large number of requests may be sent one PIM core, which becomes the performance bottleneck.
On the other hand, even existing concurrent skip-list algorithms in which threads execute
their operations by themselves in parallel cannot have good performance either,
since concurrent updates (i.e., add() and delete()) within a small range conflict with one another.
Thus, we believe a PIM-managed skip-list can achieve competitive throughput if each PIM core can
execute multiple read-only requests (i.e., contains()) and at most one update request efficiently.
We have assumed each PIM core can only deal with one request at a time,
but in fact it has the potential to execute multiple requests in parallel.

Hsieh et al. \cite{hsieh2016accelerating} proposed how to design a PIM core that
can make multiple memory accesses for multiple pointer-chasing based requests in parallel.
The idea is that, after requiring a memory access for an operation request A,
it can immediately retrieve another request B without waiting for the data of the memory access for A.
The PIM core will later resume A once the data of the memory access is returned.
In other words, the PIM core can hide its memory access latency by making multiple accesses
in multiple requests in parallel.
In theory, if the sum of the latency of doing the computation between two memory accesses
for a pointer-chasing based request and the latency of switching from one request to another
is only $1/k$ of the latency of a memory access by the PIM core,
the PIM core can essentially execute $k$ requests in parallel without delaying the pointer-chasing
procedure of each request (see \cite{hsieh2016accelerating} for more details).
Those requests can therefore be thought of as requests executed in parallel
by different hardware threads of the PIM core.

Now we explain in detail how each kind of requests to a PIM-managed skip-list is executed.
For a contains($x$) request of key $x$, a PIM core simply does the search procedure for key $x$
as in a normal sequential skip-list algorithm.
For an add($x$) request, The PIM core also does the same search procedure first.
If a node of key $x$ already exists in the skip-list, the execution is completed.
Otherwise, the search procedure must has collected the predecessor and successor nodes
between which a new node of key $x$ will be inserted
(see \cite{Herlihy08} for more details, where the search procedure is denoted as the find function).
The new node of random height is then generated and inserted \textbf{from the bottom layer up}: at each layer,
the PIM core first sets the ``next node" pointer of the new node to point to its successor at the layer
and then sets the ``next node" pointer of its predecessor at the layer to point to the new node.
Similarly, for a delete($x$) request, the PIM core first does the search for key $x$.
If a node with key $x$ is in the skip-list, the PIM core removes it \textbf{from the top layer down}:
at each layer, the PIM core sets the ``next node" pointer of the node's predecessor to point to its successor.
To free the memory space of the node, the PIM core can later physically deleted it, either in a quiescent
state, or after the PIM core have completed another $k$ requests, since there are at almost $k$ contains()
requests executed concurrently with the delete($x$) request and requests after that will never reach the node.

Now we prove that this PIM-managed skip-list is linearizable.

\proof
What we need to prove is that each partition of the PIM-managed skip-list,
which is essentially a skip-list within a smaller range of keys in a single PIM vault,
is linearizable when there are at most one update request and multiple contains() executed concurrently.

We start with the linearization points of requests.
For a contains($x$) request that finds a node with key $x$ in the skip-list at some layer,
its linearization point is the moment the PIM core reads the predecessor of the node at that layer.
For a contains($x$) request that doesn't find a node with key $x$, its linearization point is the moment
the PIM core reads the predecessor of the first node with key greater than $x$ at the bottom layer
(i.e., the node at the bottom layer in the ``predecessor array" return by the find($x$) function \cite{Herlihy08}).
For an unsuccessful update to $x$, that is, a delete($x$) that doesn't find an existing node with key $x$
or an add($x$) that finds an existing node with key $x$),
its execution is in fact the same as that of a contains($x$) and so does its linearization point.
For a successful add($x$) (which doesn't find an existing node with key $x$ and needs to insert a new node),
its linearization point is the moment the PIM core modifies the ``next node" pointer of the predecessor
of the new node at the bottom layer to point to the new node
(that is, the step of inserting the new node at the bottom layer).
For a successful delete($x$) (which finds an existing node with key $x$), its linearization point is
the moment the PIM core modifies the ``next node" pointer of the predecessor of the node to point to
the successor of the node at the bottom level (that is, the step of removing the node at the bottom layer).

Since update requests are executed sequentially and contains() requests are read-only,
it is obvious that the results (i.e., responses) of update requests are consistent
with the sequential history defined by the linearization points we just described.
To see that a contains($x$) request is also correctly linearized, we first consider the case where
the last successful update to $x$ linearized before contains($x$) is a successful add($x$) and
the first successful update to $x$ linearized after contains($x$) is a successful delete($x$).
We can prove that contains($x$) must find a node with key $x$, consistent with the sequential history.
To prove it by contradiction, we assume contains($x$) doesn't find such a node and hence is linearized
at the moment it reads the predecessor of the first node with key greater than $x$ at the bottom layer.
However, since the last successful update to $x$ linearized before contains($x$) is a successful add($x$),
a node with key $x$ must have been inserted between the node contains($x$) is about to read and the first
node with key greater than $x$ at the first layer, according to the way we linearize a successful add($x$).
Therefore the node contains($x$) is about to read cannot pointer to a node with key greater than $x$,
a contradiction, and hence contains($x$) must find a node with key $x$.
By very similar proofs that are omitted here, we can show that a contains($x$) is also correctly linearized
when the last successful update to $x$ linearized before contains($x$) is a successful delete($x$), or
the first successful update to $x$ linearized after contains($x$) is a successful add($x$).
This completes the proof.
\qed
\end{comment}

\end{document}  