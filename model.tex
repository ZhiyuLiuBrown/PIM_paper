\subsection{Performance model}
\label{section:performance_model}
Based on the latency numbers in prior work on PIM memory, 
in particular on the Hybrid Memory Cube \cite{website:HMC, Azarkhish16}, 
and on the evalutation of operations in multiprocessor architectures \cite{David13},
we propose the following simple performance model to compare 
our PIM-managed algorithms with existing concurrent data structure algorithms.
For read and write operations, we assume 
$$\latcpu = 3\latpim = 3\latllc,$$
where $\latcpu$ is the latency of a memory access by a CPU,
$\latpim$ is the latency of a local memory access by a PIM core, and
$\latllc$ is the latency of a last-level cache access by a CPU.
We ignore the costs of cache accesses of other levels in our performance model,
as they are negligible in the concurrent data structure algorithms we will consider.
We assume that the latency of a CPU making an atomic operation, such as a CAS or a F\&A,
to a cache line is 
$$\latato = \latcpu,$$ 
even if the cache line is currently in cache.
This is because an atomic operation hitting the cache is usually 
as costly as a memory access by a CPU, acorrding to \cite{David13}.
When there are $k$ atomic operations competing for a cache line concurrently,
we assume that they are executed sequentially, that is,
they complete in times $\latato, 2\latato,..., k\latato$, respectively.

We assume that the size of a message sent by a PIM core or a CPU is at most 
the size of a cache line.
Given that a message transferred between a CPU and a PIM core goes through
the crossbar network, we assume that the latency for a message to arrive at its receiver is 
$$\latmes = \latcpu.$$
We make a conservative assumption that the latency of a message transferred 
between two PIM cores is also $\latmes$.
Note that the message latency we consider here is the transfer time of a message
through a message passing channel, that is, the period between the moment
when a PIM or a CPU sends off the message and the moment when
the message arrives at the buffer of its receiver.
We ignore the time spent in other parts of a message passing procedure,
such as preprocessing and constructing the message,
as it is negligible compared to the time spent in message transfer.

