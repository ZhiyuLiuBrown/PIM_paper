\section{Performance Model}
%\subsection{Performance model}
\label{section:performance_model}
We propose the following simple performance model to compare 
our PIM-managed data structures with existing concurrent data structures.
For read and write operations, we assume 
$$\latcpu = r_1\latpim = r_2\latllc$$
where $\latcpu$ is the latency of a memory access by a CPU,
$\latpim$ is the latency of a local memory access by a PIM core, and
$\latllc$ is the latency of a last-level cache access by a CPU.
Based on the latency numbers in prior work on PIM memory, 
in particular on the Hybrid Memory Cube \cite{website:HMC, Azarkhish16}, 
and on the evaluation of operations in multiprocessor architectures \cite{David13},
we may further assume 
$$r_1 = r_2 = 3.$$ 
The latencies of operations may vary significantly on different machines.  
Our assumption that $r_1 = r_2 = 3$ is mainly to make the performance analysis later in the paper 
more concrete with actual latency numbers. 
In our performance model, we ignore the costs of accesses to other cache levels, such as L1 or L2, 
as they are negligible in the concurrent data structures we consider.

We assume that the latency of a CPU performing an atomic operation, such as a CAS or a F\&A,
to a cache line is 
$$\latato = r_3\latcpu$$ 
where $r_3 = 1$, even if the cache line is currently in the cache.
This is because an atomic operation hitting in the cache is usually 
as costly as a memory access by a CPU~\cite{David13}.
When there are $k$ atomic operations competing for a cache line concurrently,
we assume that they are executed sequentially, that is,
they complete in times $\latato, 2\latato,..., k\cdot\latato$, respectively.

We also assume that the size of a message sent by a PIM core or a CPU core is at most 
the size of a cache line.
Given that a message transferred between a CPU and a PIM core goes through
the crossbar network, we assume that the latency for a message to arrive at its receiver is 
$$\latmes = \latcpu$$
We make the conservative assumption that the latency of a message transferred 
between two PIM cores is also $\latmes$.
Note that the message latency we consider here is the transfer time of a message
through a message passing channel, that is, the elapsed time between the moment 
when a PIM or a CPU core finishes sending off the message and the moment when the message arrives at the buffer of its receiver.
We ignore the time spent in other parts of a message passing procedure,
such as in \emph{preprocessing and constructing the message}, and in \emph{actually sending the message},
as it is negligible compared to the time spent in the message transfer \cite{Azarkhish16}.