\section{Performance Model}
%\subsection{Performance model}
\label{section:performance_model}
We propose the following simple performance model to compare 
our PIM-managed algorithms with existing concurrent data structure algorithms.
For read and write operations, we assume 
$$\latcpu = r_1\latpim = r_2\latllc$$
where $\latcpu$ is the latency of a memory access by a CPU,
$\latpim$ is the latency of a local memory access by a PIM core, and
$\latllc$ is the latency of a last-level cache access by a CPU.
Based on the latency numbers in prior work on PIM memory, 
in particular on the Hybrid Memory Cube \cite{website:HMC, Azarkhish16}, 
and on the evaluation of operations in multiprocessor architectures \cite{David13},
we may further assume 
$$r_1 = r_2 = 3.$$ 
The latencies of operations may vary significantly on different machines.  
Our assumption that $r_1 = r_2 = 3$ is mainly to make the performance analysis later in the paper 
more concrete with certain latency numbers. 
We ignore the costs of cache accesses of other levels in our performance model,
as they are negligible in the concurrent data structure algorithms we will consider.

We assume that the latency of a CPU performing an atomic operation, such as a CAS or a F\&A,
to a cache line is 
$$\latato = r_3\latcpu$$ 
where $r_3 = 1$, even if the cache line is currently in cache.
This is because an atomic operation hitting in the cache is usually 
as costly as a memory access by a CPU~\cite{David13}.
When there are $k$ atomic operations competing for a cache line concurrently,
we assume that they are executed sequentially, that is,
they complete in times $\latato, 2\latato,..., k\cdot\latato$, respectively.

We also assume that the size of a message sent by a PIM core or a CPU core is at most 
the size of a cache line.
Given that a message transferred between a CPU and a PIM core goes through
the crossbar network, we assume that the latency for a message to arrive at its receiver is 
$$\latmes = \latcpu$$
We make the conservative assumption that the latency of a message transferred 
between two PIM cores is also $\latmes$.
Note that the message latency we consider here is the transfer time of a message
through a message passing channel, that is, the elapsed time between 
when a PIM or a CPU core finishes sending off the message and when the message arrives at the buffer of its receiver.
We ignore the time spent in other parts of a message passing procedure,
such as \emph{preprocessing and constructing the message}, and \emph{a PIM or a CPU core sending off the message},
as it is negligible compared to the time spent in the message transfer \cite{Azarkhish16}.